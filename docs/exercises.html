<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Exercises | ml4ec - Machine Learning for Eddy Covariance data</title>
  <meta name="description" content="This is a tutorial for a workshop (1 day), introducing machine learning using R." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Exercises | ml4ec - Machine Learning for Eddy Covariance data" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a tutorial for a workshop (1 day), introducing machine learning using R." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Exercises | ml4ec - Machine Learning for Eddy Covariance data" />
  
  <meta name="twitter:description" content="This is a tutorial for a workshop (1 day), introducing machine learning using R." />
  

<meta name="author" content="Benjamin Stocker" />


<meta name="date" content="2021-09-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="training.html"/>
<link rel="next" href="solutions.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">ml4ec</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Set up</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#apps"><i class="fa fa-check"></i><b>1.1</b> Apps</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#libraries"><i class="fa fa-check"></i><b>1.2</b> Libraries</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#learning-objectives"><i class="fa fa-check"></i><b>2.1</b> Learning objectives</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#some-primers"><i class="fa fa-check"></i><b>2.2</b> Some primers</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#overfitting"><i class="fa fa-check"></i><b>2.3</b> Overfitting</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#our-modelling-challenge"><i class="fa fa-check"></i><b>2.4</b> Our modelling challenge</a></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#data"><i class="fa fa-check"></i><b>2.5</b> Data</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introduction.html"><a href="introduction.html#available-variables"><i class="fa fa-check"></i><b>2.5.1</b> Available variables</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#more-primers"><i class="fa fa-check"></i><b>2.6</b> More primers</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="introduction.html"><a href="introduction.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>2.6.1</b> K-nearest neighbours</a></li>
<li class="chapter" data-level="2.6.2" data-path="introduction.html"><a href="introduction.html#random-forest"><i class="fa fa-check"></i><b>2.6.2</b> Random Forest</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-splitting.html"><a href="data-splitting.html"><i class="fa fa-check"></i><b>3</b> Data splitting</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data-splitting.html"><a href="data-splitting.html#reading-and-wrangling-data"><i class="fa fa-check"></i><b>3.1</b> Reading and wrangling data</a></li>
<li class="chapter" data-level="3.2" data-path="data-splitting.html"><a href="data-splitting.html#splitting-into-testing-and-training-sets"><i class="fa fa-check"></i><b>3.2</b> Splitting into testing and training sets</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="preprocessing.html"><a href="preprocessing.html"><i class="fa fa-check"></i><b>4</b> Pre-processing</a>
<ul>
<li class="chapter" data-level="4.1" data-path="preprocessing.html"><a href="preprocessing.html#dealing-with-missingness-and-bad-data"><i class="fa fa-check"></i><b>4.1</b> Dealing with missingness and bad data</a></li>
<li class="chapter" data-level="4.2" data-path="preprocessing.html"><a href="preprocessing.html#standardization"><i class="fa fa-check"></i><b>4.2</b> Standardization</a></li>
<li class="chapter" data-level="4.3" data-path="preprocessing.html"><a href="preprocessing.html#more-pre-processing"><i class="fa fa-check"></i><b>4.3</b> More pre-processing</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-formulation.html"><a href="model-formulation.html"><i class="fa fa-check"></i><b>5</b> Model formulation</a>
<ul>
<li class="chapter" data-level="5.1" data-path="model-formulation.html"><a href="model-formulation.html#formula-notation"><i class="fa fa-check"></i><b>5.1</b> Formula notation</a></li>
<li class="chapter" data-level="5.2" data-path="model-formulation.html"><a href="model-formulation.html#the-generic-train"><i class="fa fa-check"></i><b>5.2</b> The generic <code>train()</code></a></li>
<li class="chapter" data-level="5.3" data-path="model-formulation.html"><a href="model-formulation.html#recipes"><i class="fa fa-check"></i><b>5.3</b> Recipes</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="training.html"><a href="training.html"><i class="fa fa-check"></i><b>6</b> Model training</a>
<ul>
<li class="chapter" data-level="6.1" data-path="training.html"><a href="training.html#hyperparameter-tuning"><i class="fa fa-check"></i><b>6.1</b> Hyperparameter tuning</a></li>
<li class="chapter" data-level="6.2" data-path="training.html"><a href="training.html#resampling"><i class="fa fa-check"></i><b>6.2</b> Resampling</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>7</b> Exercises</a>
<ul>
<li class="chapter" data-level="7.1" data-path="exercises.html"><a href="exercises.html#reading-and-cleaning"><i class="fa fa-check"></i><b>7.1</b> Reading and cleaning</a></li>
<li class="chapter" data-level="7.2" data-path="exercises.html"><a href="exercises.html#data-splitting-1"><i class="fa fa-check"></i><b>7.2</b> Data splitting</a></li>
<li class="chapter" data-level="7.3" data-path="exercises.html"><a href="exercises.html#linear-model"><i class="fa fa-check"></i><b>7.3</b> Linear model</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="exercises.html"><a href="exercises.html#training-1"><i class="fa fa-check"></i><b>7.3.1</b> Training</a></li>
<li class="chapter" data-level="7.3.2" data-path="exercises.html"><a href="exercises.html#prediction"><i class="fa fa-check"></i><b>7.3.2</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="exercises.html"><a href="exercises.html#knn"><i class="fa fa-check"></i><b>7.4</b> KNN</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="exercises.html"><a href="exercises.html#check-data"><i class="fa fa-check"></i><b>7.4.1</b> Check data</a></li>
<li class="chapter" data-level="7.4.2" data-path="exercises.html"><a href="exercises.html#training-2"><i class="fa fa-check"></i><b>7.4.2</b> Training</a></li>
<li class="chapter" data-level="7.4.3" data-path="exercises.html"><a href="exercises.html#prediction-1"><i class="fa fa-check"></i><b>7.4.3</b> Prediction</a></li>
<li class="chapter" data-level="7.4.4" data-path="exercises.html"><a href="exercises.html#sample-hyperparameters"><i class="fa fa-check"></i><b>7.4.4</b> Sample hyperparameters</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="exercises.html"><a href="exercises.html#random-forest-1"><i class="fa fa-check"></i><b>7.5</b> Random forest</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="exercises.html"><a href="exercises.html#training-3"><i class="fa fa-check"></i><b>7.5.1</b> Training</a></li>
<li class="chapter" data-level="7.5.2" data-path="exercises.html"><a href="exercises.html#prediction-2"><i class="fa fa-check"></i><b>7.5.2</b> Prediction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="solutions.html"><a href="solutions.html"><i class="fa fa-check"></i><b>8</b> Solutions</a>
<ul>
<li class="chapter" data-level="8.1" data-path="solutions.html"><a href="solutions.html#reading-and-cleaning-1"><i class="fa fa-check"></i><b>8.1</b> Reading and cleaning</a></li>
<li class="chapter" data-level="8.2" data-path="solutions.html"><a href="solutions.html#data-splitting-2"><i class="fa fa-check"></i><b>8.2</b> Data splitting</a></li>
<li class="chapter" data-level="8.3" data-path="solutions.html"><a href="solutions.html#linear-model-1"><i class="fa fa-check"></i><b>8.3</b> Linear model</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="solutions.html"><a href="solutions.html#training-4"><i class="fa fa-check"></i><b>8.3.1</b> Training</a></li>
<li class="chapter" data-level="8.3.2" data-path="solutions.html"><a href="solutions.html#prediction-3"><i class="fa fa-check"></i><b>8.3.2</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="solutions.html"><a href="solutions.html#knn-1"><i class="fa fa-check"></i><b>8.4</b> KNN</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="solutions.html"><a href="solutions.html#check-data-1"><i class="fa fa-check"></i><b>8.4.1</b> Check data</a></li>
<li class="chapter" data-level="8.4.2" data-path="solutions.html"><a href="solutions.html#training-5"><i class="fa fa-check"></i><b>8.4.2</b> Training</a></li>
<li class="chapter" data-level="8.4.3" data-path="solutions.html"><a href="solutions.html#prediction-4"><i class="fa fa-check"></i><b>8.4.3</b> Prediction</a></li>
<li class="chapter" data-level="8.4.4" data-path="solutions.html"><a href="solutions.html#sample-hyperparameters-1"><i class="fa fa-check"></i><b>8.4.4</b> Sample hyperparameters</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="solutions.html"><a href="solutions.html#random-forest-2"><i class="fa fa-check"></i><b>8.5</b> Random forest</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="solutions.html"><a href="solutions.html#training-6"><i class="fa fa-check"></i><b>8.5.1</b> Training</a></li>
<li class="chapter" data-level="8.5.2" data-path="solutions.html"><a href="solutions.html#prediction-5"><i class="fa fa-check"></i><b>8.5.2</b> Prediction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ml4ec - Machine Learning for Eddy Covariance data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="exercises" class="section level1" number="7">
<h1><span class="header-section-number">Chapter 7</span> Exercises</h1>
<p>Now that you are familiar with the basic steps for supervised machine learning, you can get your hands on the data yourself and implement code for addressing the modelling task outlined in Chapter <a href="#motivation"><strong>??</strong></a>.</p>
<div id="reading-and-cleaning" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Reading and cleaning</h2>
<p>Read the CSV file <code>"./data/FLX_CH-Dav_FLUXNET2015_FULLSET_DD_1997-2014_1-3.csv"</code>, select all variables with name ending with <code>"_F"</code>, the variables <code>"TIMESTAMP"</code>, <code>"GPP_NT_VUT_REF"</code>, and <code>"NEE_VUT_REF_QC"</code>, and drop all variables that contain <code>"JSB"</code> in their name. Then convert the variable <code>"TIMESTAMP"</code> to a date-time object with the function <code>ymd()</code> from the <em>lubridate</em> package, and interpret all values <code>-9999</code> as missing values. Then, set all values of <code>"GPP_NT_VUT_REF"</code> to missing if the corresponding quality control variable indicates that less than 90% are measured data points. Finally, drop the variable <code>"NEE_VUT_REF_QC"</code> - we won’t use it anymore.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="exercises.html#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="do">## write your code here</span></span></code></pre></div>
</div>
<div id="data-splitting-1" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Data splitting</h2>
<p>Split the data a training and testing set, that contain 70% and 30% of the total available data, respectively.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="exercises.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="do">## write your code here</span></span></code></pre></div>
</div>
<div id="linear-model" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Linear model</h2>
<div id="training-1" class="section level3" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> Training</h3>
<p>Fit a linear regression model using the base-R function <code>lm()</code> and the training set. The target variable is <code>"GPP_NT_VUT_REF"</code>, and predictor variables are all available meterological variables in the dataset. Answer the following questions:</p>
<ul>
<li>What is the <span class="math inline">\(R^2\)</span> of predicted vs. observed <code>"GPP_NT_VUT_REF"</code>?</li>
<li>Is the linear regression slope significantly different from zero for all predictors?</li>
<li>Is a linear regression model with “poor” predictors removed better supported by the data than a model including all predictors?</li>
</ul>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="exercises.html#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="do">## write your code here</span></span></code></pre></div>
<p>Use caret and the function <code>train()</code> for fitting the same linear regression model (with all predictors) on the same data. Does it yield identical results as using <code>lm()</code> directly? You will have to set the argument <code>trControl</code> accordingly to avoid resampling, and instead fit the model on the all data in <code>ddf_train</code>. You can use <code>summary()</code> also on the object returned by the function <code>train()</code>.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="exercises.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="do">## write your code here</span></span></code></pre></div>
</div>
<div id="prediction" class="section level3" number="7.3.2">
<h3><span class="header-section-number">7.3.2</span> Prediction</h3>
<p>With the model containing all predictors and fitted on <code>ddf_train</code>, make predictions using first <code>ddf_train</code> and then <code>ddf_test</code>. Compute the <span class="math inline">\(R^2\)</span> and the root-mean-square error, and visualise modelled vs. observed values to evaluate both predictions.</p>
<p>Do you expect the linear regression model trained on <code>ddf_train</code> to predict substantially better on <code>ddf_train</code> than on <code>ddf_test</code>? Why (not)?</p>
<p>Hints:</p>
<ul>
<li>To calculate predictions, use the generic function <code>predict()</code> with the argument <code>newdata = ...</code>.</li>
<li>The <span class="math inline">\(R^2\)</span> can be extracted from the model object as <code>summary(model_object)$r.squared</code>, or is (as the RMSE) given in the metrics data frame returned by <code>metrics()</code> from the <em>yardstick</em> library.</li>
<li>For visualisation the model performance, consider a scatterplot, or (better) a plot that reveals the density of overlapping points. (We’re plotting information from over 4000 data points here!)</li>
</ul>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="exercises.html#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="do">## write your code here</span></span></code></pre></div>
</div>
</div>
<div id="knn" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> KNN</h2>
<div id="check-data" class="section level3" number="7.4.1">
<h3><span class="header-section-number">7.4.1</span> Check data</h3>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="exercises.html#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="do">## write your code here</span></span></code></pre></div>
<p>The variable <code>PA_F</code> looks weird and was not significant in the linear model. Therefore, we won’t use it for the models below.</p>
</div>
<div id="training-2" class="section level3" number="7.4.2">
<h3><span class="header-section-number">7.4.2</span> Training</h3>
<p>Fit two KNN models on <code>ddf_train</code> (excluding <code>"PA_F"</code>), one with <span class="math inline">\(k = 2\)</span> and one with <span class="math inline">\(k = 30\)</span>, both without resampling. Use the RMSE as the loss function. Center and scale data as part of the pre-processing and model formulation specification using the function <code>recipe()</code>.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="exercises.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="do">## write your code here</span></span></code></pre></div>
</div>
<div id="prediction-1" class="section level3" number="7.4.3">
<h3><span class="header-section-number">7.4.3</span> Prediction</h3>
<p>With the two models fitted above, predict <code>"GPP_NT_VUT_REF"</code> for both and training and the testing sets, and evaluate them as above (metrics and visualisation).</p>
<p>Which model do you expect to perform better on the training set and which to perform better on the testing set? Why? Do you find evidence for overfitting in any of the models?</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="exercises.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="do">## write your code here</span></span></code></pre></div>
</div>
<div id="sample-hyperparameters" class="section level3" number="7.4.4">
<h3><span class="header-section-number">7.4.4</span> Sample hyperparameters</h3>
<p>Train a KNN model with hyperparameter (<span class="math inline">\(k\)</span>) tuned, and with five-fold cross validation, using the training set. As the loss function, use RMSE. Sample the following values for <span class="math inline">\(k\)</span>: 2, 5, 10, 15, 18, 20, 22, 24, 26, 30, 35, 40, 60, 100. Visualise the RMSE as a function of <span class="math inline">\(k\)</span>.</p>
<p>Hint:</p>
<ul>
<li>The visualisation of cross-validation results can be visualised with the <code>plot(model_object)</code> of <code>ggplot(model_object)</code>.</li>
</ul>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="exercises.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="do">## write your code here</span></span></code></pre></div>
</div>
</div>
<div id="random-forest-1" class="section level2" number="7.5">
<h2><span class="header-section-number">7.5</span> Random forest</h2>
<div id="training-3" class="section level3" number="7.5.1">
<h3><span class="header-section-number">7.5.1</span> Training</h3>
<p>Fit a random forest model with <code>ddf_train</code> and all predictors excluding <code>"PA_F"</code> and five-fold cross validation. Use RMSE as the loss function.</p>
<p>Hints:</p>
<ul>
<li>Use the package <em>ranger</em> which implements the random forest algorithm.</li>
<li>See <a href="https://topepo.github.io/caret/available-models.html">here</a> for information about hyperparameters available for tuning with caret.</li>
<li>Set the argument <code>savePredictions = "final"</code> of function <code>trainControl()</code>.</li>
</ul>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="exercises.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="do">## write your code here</span></span></code></pre></div>
</div>
<div id="prediction-2" class="section level3" number="7.5.2">
<h3><span class="header-section-number">7.5.2</span> Prediction</h3>
<p>Evaluate the trained model on the training and on the test set, giving metrics and a visualisation as above.</p>
<p>How are differences in performance to be interpreted? Compare the performances of linear regression, KNN, and random forest, considering the evaluation on the test set.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="exercises.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="do">## write your code here</span></span></code></pre></div>
<p>Show the model performance (metrics and visualisation) on the validation sets all cross validation folds combined.</p>
<p>Do you expect it to be more similar to the model performance on the training set or the testing set in the evaluation above? Why?</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="exercises.html#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="do">## write your code here</span></span></code></pre></div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="training.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="solutions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ml4ec_workshop.pdf", "ml4ec_workshop.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
