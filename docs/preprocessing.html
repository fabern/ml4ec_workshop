<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Pre-processing | ml4ec - Machine Learning for Eddy Covariance data</title>
  <meta name="description" content="This is a tutorial for a workshop (1 day), introducing machine learning using R." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Pre-processing | ml4ec - Machine Learning for Eddy Covariance data" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a tutorial for a workshop (1 day), introducing machine learning using R." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Pre-processing | ml4ec - Machine Learning for Eddy Covariance data" />
  
  <meta name="twitter:description" content="This is a tutorial for a workshop (1 day), introducing machine learning using R." />
  

<meta name="author" content="Benjamin Stocker" />


<meta name="date" content="2021-09-02" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data-splitting.html"/>
<link rel="next" href="model-formulation.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">ml4ec</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Set up</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#apps"><i class="fa fa-check"></i><b>1.1</b> Apps</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#libraries"><i class="fa fa-check"></i><b>1.2</b> Libraries</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#learning-objectives"><i class="fa fa-check"></i><b>2.1</b> Learning objectives</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#some-primers"><i class="fa fa-check"></i><b>2.2</b> Some primers</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#overfitting"><i class="fa fa-check"></i><b>2.3</b> Overfitting</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#our-modelling-challenge"><i class="fa fa-check"></i><b>2.4</b> Our modelling challenge</a></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#data"><i class="fa fa-check"></i><b>2.5</b> Data</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introduction.html"><a href="introduction.html#available-variables"><i class="fa fa-check"></i><b>2.5.1</b> Available variables</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#more-primers"><i class="fa fa-check"></i><b>2.6</b> More primers</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="introduction.html"><a href="introduction.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>2.6.1</b> K-nearest neighbours</a></li>
<li class="chapter" data-level="2.6.2" data-path="introduction.html"><a href="introduction.html#random-forest"><i class="fa fa-check"></i><b>2.6.2</b> Random Forest</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-splitting.html"><a href="data-splitting.html"><i class="fa fa-check"></i><b>3</b> Data splitting</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data-splitting.html"><a href="data-splitting.html#reading-and-wrangling-data"><i class="fa fa-check"></i><b>3.1</b> Reading and wrangling data</a></li>
<li class="chapter" data-level="3.2" data-path="data-splitting.html"><a href="data-splitting.html#splitting-into-testing-and-training-sets"><i class="fa fa-check"></i><b>3.2</b> Splitting into testing and training sets</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="preprocessing.html"><a href="preprocessing.html"><i class="fa fa-check"></i><b>4</b> Pre-processing</a>
<ul>
<li class="chapter" data-level="4.1" data-path="preprocessing.html"><a href="preprocessing.html#dealing-with-missingness-and-bad-data"><i class="fa fa-check"></i><b>4.1</b> Dealing with missingness and bad data</a></li>
<li class="chapter" data-level="4.2" data-path="preprocessing.html"><a href="preprocessing.html#standardization"><i class="fa fa-check"></i><b>4.2</b> Standardization</a></li>
<li class="chapter" data-level="4.3" data-path="preprocessing.html"><a href="preprocessing.html#more-pre-processing"><i class="fa fa-check"></i><b>4.3</b> More pre-processing</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-formulation.html"><a href="model-formulation.html"><i class="fa fa-check"></i><b>5</b> Model formulation</a>
<ul>
<li class="chapter" data-level="5.1" data-path="model-formulation.html"><a href="model-formulation.html#formula-notation"><i class="fa fa-check"></i><b>5.1</b> Formula notation</a></li>
<li class="chapter" data-level="5.2" data-path="model-formulation.html"><a href="model-formulation.html#the-generic-train"><i class="fa fa-check"></i><b>5.2</b> The generic <code>train()</code></a></li>
<li class="chapter" data-level="5.3" data-path="model-formulation.html"><a href="model-formulation.html#recipes"><i class="fa fa-check"></i><b>5.3</b> Recipes</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="training.html"><a href="training.html"><i class="fa fa-check"></i><b>6</b> Model training</a>
<ul>
<li class="chapter" data-level="6.1" data-path="training.html"><a href="training.html#hyperparameter-tuning"><i class="fa fa-check"></i><b>6.1</b> Hyperparameter tuning</a></li>
<li class="chapter" data-level="6.2" data-path="training.html"><a href="training.html#resampling"><i class="fa fa-check"></i><b>6.2</b> Resampling</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>7</b> Exercises</a>
<ul>
<li class="chapter" data-level="7.1" data-path="exercises.html"><a href="exercises.html#reading-and-cleaning"><i class="fa fa-check"></i><b>7.1</b> Reading and cleaning</a></li>
<li class="chapter" data-level="7.2" data-path="exercises.html"><a href="exercises.html#data-splitting-1"><i class="fa fa-check"></i><b>7.2</b> Data splitting</a></li>
<li class="chapter" data-level="7.3" data-path="exercises.html"><a href="exercises.html#linear-model"><i class="fa fa-check"></i><b>7.3</b> Linear model</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="exercises.html"><a href="exercises.html#training-1"><i class="fa fa-check"></i><b>7.3.1</b> Training</a></li>
<li class="chapter" data-level="7.3.2" data-path="exercises.html"><a href="exercises.html#prediction"><i class="fa fa-check"></i><b>7.3.2</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="exercises.html"><a href="exercises.html#knn"><i class="fa fa-check"></i><b>7.4</b> KNN</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="exercises.html"><a href="exercises.html#check-data"><i class="fa fa-check"></i><b>7.4.1</b> Check data</a></li>
<li class="chapter" data-level="7.4.2" data-path="exercises.html"><a href="exercises.html#training-2"><i class="fa fa-check"></i><b>7.4.2</b> Training</a></li>
<li class="chapter" data-level="7.4.3" data-path="exercises.html"><a href="exercises.html#prediction-1"><i class="fa fa-check"></i><b>7.4.3</b> Prediction</a></li>
<li class="chapter" data-level="7.4.4" data-path="exercises.html"><a href="exercises.html#sample-hyperparameters"><i class="fa fa-check"></i><b>7.4.4</b> Sample hyperparameters</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="exercises.html"><a href="exercises.html#random-forest-1"><i class="fa fa-check"></i><b>7.5</b> Random forest</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="exercises.html"><a href="exercises.html#training-3"><i class="fa fa-check"></i><b>7.5.1</b> Training</a></li>
<li class="chapter" data-level="7.5.2" data-path="exercises.html"><a href="exercises.html#prediction-2"><i class="fa fa-check"></i><b>7.5.2</b> Prediction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="solutions.html"><a href="solutions.html"><i class="fa fa-check"></i><b>8</b> Solutions</a>
<ul>
<li class="chapter" data-level="8.1" data-path="solutions.html"><a href="solutions.html#reading-and-cleaning-1"><i class="fa fa-check"></i><b>8.1</b> Reading and cleaning</a></li>
<li class="chapter" data-level="8.2" data-path="solutions.html"><a href="solutions.html#data-splitting-2"><i class="fa fa-check"></i><b>8.2</b> Data splitting</a></li>
<li class="chapter" data-level="8.3" data-path="solutions.html"><a href="solutions.html#linear-model-1"><i class="fa fa-check"></i><b>8.3</b> Linear model</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="solutions.html"><a href="solutions.html#training-4"><i class="fa fa-check"></i><b>8.3.1</b> Training</a></li>
<li class="chapter" data-level="8.3.2" data-path="solutions.html"><a href="solutions.html#prediction-3"><i class="fa fa-check"></i><b>8.3.2</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="solutions.html"><a href="solutions.html#knn-1"><i class="fa fa-check"></i><b>8.4</b> KNN</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="solutions.html"><a href="solutions.html#check-data-1"><i class="fa fa-check"></i><b>8.4.1</b> Check data</a></li>
<li class="chapter" data-level="8.4.2" data-path="solutions.html"><a href="solutions.html#training-5"><i class="fa fa-check"></i><b>8.4.2</b> Training</a></li>
<li class="chapter" data-level="8.4.3" data-path="solutions.html"><a href="solutions.html#prediction-4"><i class="fa fa-check"></i><b>8.4.3</b> Prediction</a></li>
<li class="chapter" data-level="8.4.4" data-path="solutions.html"><a href="solutions.html#sample-hyperparameters-1"><i class="fa fa-check"></i><b>8.4.4</b> Sample hyperparameters</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="solutions.html"><a href="solutions.html#random-forest-2"><i class="fa fa-check"></i><b>8.5</b> Random forest</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="solutions.html"><a href="solutions.html#training-6"><i class="fa fa-check"></i><b>8.5.1</b> Training</a></li>
<li class="chapter" data-level="8.5.2" data-path="solutions.html"><a href="solutions.html#prediction-5"><i class="fa fa-check"></i><b>8.5.2</b> Prediction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ml4ec - Machine Learning for Eddy Covariance data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="preprocessing" class="section level1" number="4">
<h1><span class="header-section-number">Chapter 4</span> Pre-processing</h1>
<p>Skewed data, outliers, and values covering multiple orders of magnitude can create difficulties for certain ML algorithms, e.g., or K-nearest neighbours, or neural networks. Other algorithms, like tree-based methods (e.g., Random Forest), are more robust against such issues.</p>
<div id="dealing-with-missingness-and-bad-data" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Dealing with missingness and bad data</h2>
<p>Several ML algorithms require missing values to be removed. That is, if any of the cells in one row has a missing value, the entire cell gets removed. Data may be missing for several reasons. Some yield random patterns of missing data, others not. In the latter case, we can speak of <em>informative missingness</em> (Kuhn &amp; Johnson, 2003) and its information can be used for predictions. For categorical data, we may replace such data with <code>"none"</code> (instead of <code>NA</code>), while randomly missing data may be dropped altogether. Some ML algorithms (mainly tree-based methods, e.g., random forest) can handle missing values. However, when comparing the performance of alternative ML algorithms, they should be tested with the same data and removing missing data should be done beforehand.</p>
<p>Visualising missing data is essential for making decisions about dropping rows with missing data versus removing predictors from the model (which would imply too much data removal). The cells with missing data in a data frame can be eaily visualised e.g. with <code>vis_miss()</code> from the <em>visdat</em> package.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="preprocessing.html#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(visdat)</span>
<span id="cb7-2"><a href="preprocessing.html#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">vis_miss</span>(</span>
<span id="cb7-3"><a href="preprocessing.html#cb7-3" aria-hidden="true" tabindex="-1"></a>  ddf,</span>
<span id="cb7-4"><a href="preprocessing.html#cb7-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">cluster =</span> <span class="cn">FALSE</span>, </span>
<span id="cb7-5"><a href="preprocessing.html#cb7-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">warn_large_data =</span> <span class="cn">FALSE</span></span>
<span id="cb7-6"><a href="preprocessing.html#cb7-6" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p><img src="ml4ec_workshop_files/figure-html/unnamed-chunk-14-1.png" width="696" style="display: block; margin: auto;" /></p>
<p>The question about what is “bad data” and whether or when it should be removed is often critical. Such decisions are important to keep track of and should be reported as transparently as possible in publications. In reality, where the data generation process may start in the field with actual human beings writing notes in a lab book, and where the human collecting the data is often not the same as the human writing the paper, it’s often more difficult to keep track of such decisions. As a general principle, it is advisable to design data records such that decisions made during its process remain transparent throughout all stages of the workflow and that sufficient information be collected to enable later revisions of particularly critical decisions.</p>
</div>
<div id="standardization" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Standardization</h2>
<p>Several algorithms explicitly require data to be standardized. That is, values of all predictors vary within a comparable range. The necessity of this step becomes obvious when considering neural networks, the activation functions of each node have to deal with standardized inputs. In other words, inputs have to vary over the same range, expecting a mean of zero and standard deviation of one.)</p>
<p>To get a quick overview of the distribution of all variables (columns) in our data frame, we can use the <em>skimr</em> package.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="preprocessing.html#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(skimr)</span>
<span id="cb8-2"><a href="preprocessing.html#cb8-2" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="fu">skim</span>(ddf))</span></code></pre></div>
<table>
<colgroup>
<col width="5%" />
<col width="7%" />
<col width="5%" />
<col width="7%" />
<col width="5%" />
<col width="5%" />
<col width="6%" />
<col width="7%" />
<col width="6%" />
<col width="5%" />
<col width="5%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_type</th>
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">Date.min</th>
<th align="left">Date.max</th>
<th align="left">Date.median</th>
<th align="right">Date.n_unique</th>
<th align="right">numeric.mean</th>
<th align="right">numeric.sd</th>
<th align="right">numeric.p0</th>
<th align="right">numeric.p25</th>
<th align="right">numeric.p50</th>
<th align="right">numeric.p75</th>
<th align="right">numeric.p100</th>
<th align="left">numeric.hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Date</td>
<td align="left">TIMESTAMP</td>
<td align="right">0</td>
<td align="right">1.0000000</td>
<td align="left">1997-01-01</td>
<td align="left">2014-12-31</td>
<td align="left">2005-12-31</td>
<td align="right">6574</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="left">NA</td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">GPP_NT_VUT_REF</td>
<td align="right">395</td>
<td align="right">0.9399148</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="right">NA</td>
<td align="right">3.218728</td>
<td align="right">2.7569372</td>
<td align="right">-4.22996</td>
<td align="right">0.7730585</td>
<td align="right">2.87334</td>
<td align="right">5.44718</td>
<td align="right">12.2567</td>
<td align="left">▁▇▆▃▁</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">TA_F</td>
<td align="right">0</td>
<td align="right">1.0000000</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="right">NA</td>
<td align="right">3.517397</td>
<td align="right">6.6562542</td>
<td align="right">-21.92400</td>
<td align="right">-1.5565000</td>
<td align="right">3.44450</td>
<td align="right">8.72200</td>
<td align="right">20.6870</td>
<td align="left">▁▂▇▇▂</td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">SW_IN_F</td>
<td align="right">0</td>
<td align="right">1.0000000</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="right">NA</td>
<td align="right">150.785747</td>
<td align="right">85.0156424</td>
<td align="right">3.30300</td>
<td align="right">78.2630000</td>
<td align="right">136.67700</td>
<td align="right">215.54125</td>
<td align="right">365.8880</td>
<td align="left">▆▇▆▅▂</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">LW_IN_F</td>
<td align="right">0</td>
<td align="right">1.0000000</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="right">NA</td>
<td align="right">269.771156</td>
<td align="right">41.9073945</td>
<td align="right">138.12500</td>
<td align="right">239.3937500</td>
<td align="right">272.62150</td>
<td align="right">303.36150</td>
<td align="right">364.9070</td>
<td align="left">▁▃▇▇▂</td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">VPD_F</td>
<td align="right">0</td>
<td align="right">1.0000000</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="right">NA</td>
<td align="right">2.865737</td>
<td align="right">2.3936778</td>
<td align="right">0.00100</td>
<td align="right">0.9950000</td>
<td align="right">2.23900</td>
<td align="right">4.05775</td>
<td align="right">16.5650</td>
<td align="left">▇▃▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">PA_F</td>
<td align="right">0</td>
<td align="right">1.0000000</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="right">NA</td>
<td align="right">83.564688</td>
<td align="right">0.7261651</td>
<td align="right">80.37300</td>
<td align="right">83.1600000</td>
<td align="right">83.68300</td>
<td align="right">84.07200</td>
<td align="right">85.6330</td>
<td align="left">▁▁▅▇▁</td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">P_F</td>
<td align="right">0</td>
<td align="right">1.0000000</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="right">NA</td>
<td align="right">2.304499</td>
<td align="right">5.7860345</td>
<td align="right">0.00000</td>
<td align="right">0.0000000</td>
<td align="right">0.00000</td>
<td align="right">1.60000</td>
<td align="right">92.1000</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">WS_F</td>
<td align="right">0</td>
<td align="right">1.0000000</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="right">NA</td>
<td align="right">1.991029</td>
<td align="right">0.6604529</td>
<td align="right">0.32800</td>
<td align="right">1.5410000</td>
<td align="right">1.92200</td>
<td align="right">2.33900</td>
<td align="right">6.5390</td>
<td align="left">▃▇▁▁▁</td>
</tr>
</tbody>
</table>
<p>We see for example, that typical values of <code>LW_IN_F</code> are by a factor 100 larger than values of <code>VPD_F</code>. KNN uses the distance from neighbouring points for predictions. Obviously, in this case here, any distance would be dominated by <code>LW_IN_F</code> and distances in the “direction” of <code>VPD_F</code>, even when relatively large, would not be influential, neither for a Euclidean nor a Manhattan distance (see <a href="introduction.html#introduction">2</a>). In neural networks, activation functions take values in a given range (0-1). Thus, for both algorithms, data has to be standardized prior to model training.</p>
<p>Standardization is done, for example, by dividing each variable, that is all values in one column, by the standard deviation of that variable, and then subtracting its mean. This way, the resulting standardized values are centered around 0, and scaled such that a value of 1 means that the data point is one standard deviation above the mean of the respective variable (column). When applied to all predictors individually, the absolute values of their variations can be directly compared and only then it can be meaningfully used for determining the distance.</p>
<p>Standardization can be done not only by centering and scaling (as described above), but also by <em>scaling to within range</em>, where values are scaled such that the minimum value within each variable (column) is 0 and the maximum is 1.</p>
<p>In order to avoid <em>data leakage</em>, centering and scaling has to be done separately for each split into training and validation data (more on that later). In other words, don’t center and scale the entire data frame with the mean and standard deviation derived from the entire data frame, but instead center and scale with mean and standard deviation derived from the training portion of the data, and apply that also to the validation portion, when evaluating.</p>
<p>The <em>caret</em> package takes care of this. The R package <a href="https://topepo.github.io/caret/"><strong>caret</strong></a> provides a unified interface for using different ML algorithms implemented in separate packages. The preprocessing steps applied with each resampling fold can be specified using the function <code>preProcess()</code>. More on resampling in Chapter <a href="training.html#training">6</a>.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="preprocessing.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb9-2"><a href="preprocessing.html#cb9-2" aria-hidden="true" tabindex="-1"></a>pp <span class="ot">&lt;-</span> <span class="fu">preProcess</span>(ddf_train, <span class="at">method =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>))</span></code></pre></div>
<p>As seen above for the feature engineering example, this does not return a standardized version of the data frame <code>ddf</code>. Rather, it returns the information that allows us to apply the same standardization also to other data sets. In other words, we use the distribution of values in the data set to which we applied the function to determine the centering and scaling (here: mean and standard deviation).</p>
</div>
<div id="more-pre-processing" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> More pre-processing</h2>
<p>Depending on the algorithm and the data, additional pre-processing steps may be required. You can find more information about this in the great and freely available online tutorial <a href="https://bradleyboehmke.github.io/HOML/engineering.html#target-engineering">Hands-On Machine Learning in R</a>.</p>
<p>One such additional pre-processing step is <em>imputation</em>, where missing values are imputed (gap-filled), for example by the mean of each variable respectively. Also imputation is prone to cause data leakage and must therefore be implemented as part of the resampling and training workflow. The <strong>recipes</strong> package offers a great way to deal with imputation (and also all other pre-processing steps). <a href="https://bradleyboehmke.github.io/HOML/engineering.html#impute">Here</a> is a link to learn more about it.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data-splitting.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="model-formulation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ml4ec_workshop.pdf", "ml4ec_workshop.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
