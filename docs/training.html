<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Model training | ml4ec - Machine Learning for Eddy Covariance data</title>
  <meta name="description" content="This is a tutorial for a workshop (1 day), introducing machine learning using R." />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Model training | ml4ec - Machine Learning for Eddy Covariance data" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a tutorial for a workshop (1 day), introducing machine learning using R." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Model training | ml4ec - Machine Learning for Eddy Covariance data" />
  
  <meta name="twitter:description" content="This is a tutorial for a workshop (1 day), introducing machine learning using R." />
  

<meta name="author" content="Benjamin Stocker" />


<meta name="date" content="2022-09-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="model-formulation.html"/>
<link rel="next" href="exercises.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">ml4ec</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Set up</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#apps"><i class="fa fa-check"></i><b>1.1</b> Apps</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#libraries"><i class="fa fa-check"></i><b>1.2</b> Libraries</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#learning-objectives"><i class="fa fa-check"></i><b>2.1</b> Learning objectives</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#some-primers"><i class="fa fa-check"></i><b>2.2</b> Some primers</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#overfitting"><i class="fa fa-check"></i><b>2.3</b> Overfitting</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#our-modelling-challenge"><i class="fa fa-check"></i><b>2.4</b> Our modelling challenge</a></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#data"><i class="fa fa-check"></i><b>2.5</b> Data</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introduction.html"><a href="introduction.html#available-variables"><i class="fa fa-check"></i><b>2.5.1</b> Available variables</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#more-primers"><i class="fa fa-check"></i><b>2.6</b> More primers</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="introduction.html"><a href="introduction.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>2.6.1</b> K-nearest neighbours</a></li>
<li class="chapter" data-level="2.6.2" data-path="introduction.html"><a href="introduction.html#random-forest"><i class="fa fa-check"></i><b>2.6.2</b> Random Forest</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-splitting.html"><a href="data-splitting.html"><i class="fa fa-check"></i><b>3</b> Data splitting</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data-splitting.html"><a href="data-splitting.html#reading-and-wrangling-data"><i class="fa fa-check"></i><b>3.1</b> Reading and wrangling data</a></li>
<li class="chapter" data-level="3.2" data-path="data-splitting.html"><a href="data-splitting.html#splitting-into-testing-and-training-sets"><i class="fa fa-check"></i><b>3.2</b> Splitting into testing and training sets</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="preprocessing.html"><a href="preprocessing.html"><i class="fa fa-check"></i><b>4</b> Pre-processing</a>
<ul>
<li class="chapter" data-level="4.1" data-path="preprocessing.html"><a href="preprocessing.html#dealing-with-missingness-and-bad-data"><i class="fa fa-check"></i><b>4.1</b> Dealing with missingness and bad data</a></li>
<li class="chapter" data-level="4.2" data-path="preprocessing.html"><a href="preprocessing.html#standardization"><i class="fa fa-check"></i><b>4.2</b> Standardization</a></li>
<li class="chapter" data-level="4.3" data-path="preprocessing.html"><a href="preprocessing.html#more-pre-processing"><i class="fa fa-check"></i><b>4.3</b> More pre-processing</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-formulation.html"><a href="model-formulation.html"><i class="fa fa-check"></i><b>5</b> Model formulation</a>
<ul>
<li class="chapter" data-level="5.1" data-path="model-formulation.html"><a href="model-formulation.html#formula-notation"><i class="fa fa-check"></i><b>5.1</b> Formula notation</a></li>
<li class="chapter" data-level="5.2" data-path="model-formulation.html"><a href="model-formulation.html#the-generic-train"><i class="fa fa-check"></i><b>5.2</b> The generic <code>train()</code></a></li>
<li class="chapter" data-level="5.3" data-path="model-formulation.html"><a href="model-formulation.html#recipes"><i class="fa fa-check"></i><b>5.3</b> Recipes</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="training.html"><a href="training.html"><i class="fa fa-check"></i><b>6</b> Model training</a>
<ul>
<li class="chapter" data-level="6.1" data-path="training.html"><a href="training.html#hyperparameter-tuning"><i class="fa fa-check"></i><b>6.1</b> Hyperparameter tuning</a></li>
<li class="chapter" data-level="6.2" data-path="training.html"><a href="training.html#resampling"><i class="fa fa-check"></i><b>6.2</b> Resampling</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>7</b> Exercises</a>
<ul>
<li class="chapter" data-level="7.1" data-path="exercises.html"><a href="exercises.html#reading-and-cleaning"><i class="fa fa-check"></i><b>7.1</b> Reading and cleaning</a></li>
<li class="chapter" data-level="7.2" data-path="exercises.html"><a href="exercises.html#data-splitting-1"><i class="fa fa-check"></i><b>7.2</b> Data splitting</a></li>
<li class="chapter" data-level="7.3" data-path="exercises.html"><a href="exercises.html#linear-model"><i class="fa fa-check"></i><b>7.3</b> Linear model</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="exercises.html"><a href="exercises.html#training-1"><i class="fa fa-check"></i><b>7.3.1</b> Training</a></li>
<li class="chapter" data-level="7.3.2" data-path="exercises.html"><a href="exercises.html#prediction"><i class="fa fa-check"></i><b>7.3.2</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="exercises.html"><a href="exercises.html#knn"><i class="fa fa-check"></i><b>7.4</b> KNN</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="exercises.html"><a href="exercises.html#check-data"><i class="fa fa-check"></i><b>7.4.1</b> Check data</a></li>
<li class="chapter" data-level="7.4.2" data-path="exercises.html"><a href="exercises.html#training-2"><i class="fa fa-check"></i><b>7.4.2</b> Training</a></li>
<li class="chapter" data-level="7.4.3" data-path="exercises.html"><a href="exercises.html#prediction-1"><i class="fa fa-check"></i><b>7.4.3</b> Prediction</a></li>
<li class="chapter" data-level="7.4.4" data-path="exercises.html"><a href="exercises.html#sample-hyperparameters"><i class="fa fa-check"></i><b>7.4.4</b> Sample hyperparameters</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="exercises.html"><a href="exercises.html#random-forest-1"><i class="fa fa-check"></i><b>7.5</b> Random forest</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="exercises.html"><a href="exercises.html#training-3"><i class="fa fa-check"></i><b>7.5.1</b> Training</a></li>
<li class="chapter" data-level="7.5.2" data-path="exercises.html"><a href="exercises.html#prediction-2"><i class="fa fa-check"></i><b>7.5.2</b> Prediction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="solutions.html"><a href="solutions.html"><i class="fa fa-check"></i><b>8</b> Solutions</a>
<ul>
<li class="chapter" data-level="8.1" data-path="solutions.html"><a href="solutions.html#reading-and-cleaning-1"><i class="fa fa-check"></i><b>8.1</b> Reading and cleaning</a></li>
<li class="chapter" data-level="8.2" data-path="solutions.html"><a href="solutions.html#data-splitting-2"><i class="fa fa-check"></i><b>8.2</b> Data splitting</a></li>
<li class="chapter" data-level="8.3" data-path="solutions.html"><a href="solutions.html#linear-model-1"><i class="fa fa-check"></i><b>8.3</b> Linear model</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="solutions.html"><a href="solutions.html#training-4"><i class="fa fa-check"></i><b>8.3.1</b> Training</a></li>
<li class="chapter" data-level="8.3.2" data-path="solutions.html"><a href="solutions.html#prediction-3"><i class="fa fa-check"></i><b>8.3.2</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="solutions.html"><a href="solutions.html#knn-1"><i class="fa fa-check"></i><b>8.4</b> KNN</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="solutions.html"><a href="solutions.html#check-data-1"><i class="fa fa-check"></i><b>8.4.1</b> Check data</a></li>
<li class="chapter" data-level="8.4.2" data-path="solutions.html"><a href="solutions.html#training-5"><i class="fa fa-check"></i><b>8.4.2</b> Training</a></li>
<li class="chapter" data-level="8.4.3" data-path="solutions.html"><a href="solutions.html#prediction-4"><i class="fa fa-check"></i><b>8.4.3</b> Prediction</a></li>
<li class="chapter" data-level="8.4.4" data-path="solutions.html"><a href="solutions.html#sample-hyperparameters-1"><i class="fa fa-check"></i><b>8.4.4</b> Sample hyperparameters</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="solutions.html"><a href="solutions.html#random-forest-2"><i class="fa fa-check"></i><b>8.5</b> Random forest</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="solutions.html"><a href="solutions.html#training-6"><i class="fa fa-check"></i><b>8.5.1</b> Training</a></li>
<li class="chapter" data-level="8.5.2" data-path="solutions.html"><a href="solutions.html#prediction-5"><i class="fa fa-check"></i><b>8.5.2</b> Prediction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ml4ec - Machine Learning for Eddy Covariance data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="training" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Chapter 6</span> Model training<a href="training.html#training" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Model training in supervised ML is guided by the match (or mismatch) between the predicted and observed target variable(s), that is, between <span class="math inline">\(\hat{Y}\)</span> and <span class="math inline">\(Y\)</span>. The <em>loss</em> function quantifies this mismatch (<span class="math inline">\(L(\hat{Y}, Y)\)</span>), and the algorithm takes care of progressively reducing the loss during model training. Let’s say the ML model contains two parameters and predictions can be considered a function of the two (<span class="math inline">\(\hat{Y}(w_1, w_2)\)</span>). <span class="math inline">\(Y\)</span> is actually constant. Thus, the loss function is effectively a function <span class="math inline">\(L(w_1, w_2)\)</span>. Therefore, we can consider the model training as a search of the parameter space of the machine learning model <span class="math inline">\((w_1, w_2)\)</span> to find the minimum of the loss. Common loss functions are the root mean square error (RMSE), or the mean square error (MSE), or the mean absolute error (MAE). Loss minimization is a general feature of ML model training.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-22"></span>
<img src="fig/loss_plane.png" alt="Visualization of a loss function as a plane spanned by the two parameters $w_1$ and $w_2$." width="414" />
<p class="caption">
Figure 6.1: Visualization of a loss function as a plane spanned by the two parameters <span class="math inline">\(w_1\)</span> and <span class="math inline">\(w_2\)</span>.
</p>
</div>
<p>Model training is implemented in R for different algorithms in different packages. Some algorithms are even implemented by multiple packages (e.g., <code>nnet</code> and <code>neuralnet</code> for artificial neural networks). As described in Chapter <a href="preprocessing.html#preprocessing">4</a>, the <strong>caret</strong> package provides “wrappers” that handle a large selection of different ML model implementations in different packages with a unified interface (see <a href="https://topepo.github.io/caret/available-models.html">here</a> for an overview of available models). The <strong>caret</strong> function <code>train()</code> is the centre piece. Its argument <code>metric</code> specifies the loss function and defaults to the RMSE for regression models and accuracy for classification (see sub-section on metrics below).</p>
<div id="hyperparameter-tuning" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Hyperparameter tuning<a href="training.html#hyperparameter-tuning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Practically all ML algorithms have some “knobs” to turn in order to achieve efficient model training and predictive performance. Such “knobs” are the <em>hyperparameters</em>. What these knobs are, depends on the ML algorithm.</p>
<p>For KNN, this is <code>k</code> - the number of neighbours to consider for determining distances. There is always an optimum <span class="math inline">\(k\)</span>. Obviously, if <span class="math inline">\(k = n\)</span>, we consider all observations as neighbours and each prediction is simply the mean of all observed target values <span class="math inline">\(Y\)</span>, irrespective of the predictor values. This cannot be optimal and such a model is likely underfit. On the other extreme, with <span class="math inline">\(k = 1\)</span>, the model will be strongly affected by the noise in the single nearest neighbour and its generalisability will suffer. This should be reflected in a poor performance on the validation data.</p>
<p>For random forests from the <strong>ranger</strong> package, hyperparameters are:</p>
<ul>
<li><code>mtry</code>: the number of variables to consider to make decisions, often taken as <span class="math inline">\(p/3\)</span>, where <span class="math inline">\(p\)</span> is the number of predictors.</li>
<li><code>min.node.size</code>: the number of data points at the “bottom” of each decision tree</li>
<li><code>splitrule</code>: the function applied to data in each branch of a tree, used for determining the goodness of a decision</li>
</ul>
<p>Hyperparameters usually have to be “tuned”. The optimal setting depends on the data and can therefore not be known <em>a priori</em>.</p>
<p>In <strong>caret</strong>, hyperparameter tuning is implemented as part of the <code>train()</code> function. Values of hyperparameters to consider are to be specified by the argument <code>tuneGrid</code>, which takes a data frame with column(s) named according to the name(s) of the hyperparameter(s) and rows for each combination of hyperparameters to consider.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="training.html#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="do">## do not run</span></span>
<span id="cb16-2"><a href="training.html#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">train</span>(</span>
<span id="cb16-3"><a href="training.html#cb16-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">form =</span> GPP_NT_VUT_REF <span class="sc">~</span> SW_F_IN <span class="sc">+</span> VPD_F <span class="sc">+</span> TA_F, </span>
<span id="cb16-4"><a href="training.html#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> ddf, </span>
<span id="cb16-5"><a href="training.html#cb16-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;ranger&quot;</span>,</span>
<span id="cb16-6"><a href="training.html#cb16-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>( <span class="at">.mtry =</span> <span class="fu">floor</span>(<span class="dv">6</span> <span class="sc">/</span> <span class="dv">3</span>),</span>
<span id="cb16-7"><a href="training.html#cb16-7" aria-hidden="true" tabindex="-1"></a>                          <span class="at">.min.node.size =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">9</span>,<span class="dv">15</span>, <span class="dv">30</span>),</span>
<span id="cb16-8"><a href="training.html#cb16-8" aria-hidden="true" tabindex="-1"></a>                          <span class="at">.splitrule =</span> <span class="fu">c</span>(<span class="st">&quot;variance&quot;</span>, <span class="st">&quot;maxstat&quot;</span>)),</span>
<span id="cb16-9"><a href="training.html#cb16-9" aria-hidden="true" tabindex="-1"></a>  ...</span>
<span id="cb16-10"><a href="training.html#cb16-10" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Here, <code>expand.grid()</code> is used to provide a data frame with all combinations of values provided by individual vectors.</p>
</div>
<div id="resampling" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Resampling<a href="training.html#resampling" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The goal of model training is to achieve the best possible model generalisability. That is, the best possible model performance when predicting to data that was not used for training - the test data. Resampling mimicks the comparison of predictions to the test data. Instead of using all training data, the training data is <em>resampled</em> into a number further splits into pairs of training and <em>validation</em> data. Model training is then guided by minimising the average loss determined on each resample of the validation data. Having multiple resamples (multiple <em>folds</em> of training-validation splits) avoids the loss minimization from being misguided by random peculiarities in the training and/or validation data.</p>
<p>A common resampling method is <em>k-fold cross validation</em>, where the training data is split into <em>k</em> equally sized subsets (<em>folds</em>). Then, there will be <em>k</em> iterations, where each fold is used for validation once (while the remaining folds are used for training). An extreme case is <em>leave-one-out cross validation</em>, where <em>k</em> corresponds to the number of data points.</p>
<p><img src="fig/cv.png" width="716" style="display: block; margin: auto;" /></p>
<p>To do a k-fold cross validation during model training in R, we don’t have to implement the loops around folds ourselves. The resampling procedure can be specified in the <strong>caret</strong> function <code>train()</code> with the argument <code>trControl</code>. The object that this argument takes is the output of a function call to <code>trainControl()</code>. This can be implemented in two steps. For example, to do a 10-fold cross-validation, we can write:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="training.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="do">## do not run</span></span>
<span id="cb17-2"><a href="training.html#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">train</span>(</span>
<span id="cb17-3"><a href="training.html#cb17-3" aria-hidden="true" tabindex="-1"></a>  pp, </span>
<span id="cb17-4"><a href="training.html#cb17-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> ddf_train, </span>
<span id="cb17-5"><a href="training.html#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;ranger&quot;</span>,</span>
<span id="cb17-6"><a href="training.html#cb17-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>( <span class="at">.mtry =</span> <span class="fu">floor</span>(<span class="dv">6</span> <span class="sc">/</span> <span class="dv">3</span>),</span>
<span id="cb17-7"><a href="training.html#cb17-7" aria-hidden="true" tabindex="-1"></a>                          <span class="at">.min.node.size =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">9</span>,<span class="dv">15</span>, <span class="dv">30</span>),</span>
<span id="cb17-8"><a href="training.html#cb17-8" aria-hidden="true" tabindex="-1"></a>                          <span class="at">.splitrule =</span> <span class="fu">c</span>(<span class="st">&quot;variance&quot;</span>, <span class="st">&quot;maxstat&quot;</span>)),</span>
<span id="cb17-9"><a href="training.html#cb17-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>),</span>
<span id="cb17-10"><a href="training.html#cb17-10" aria-hidden="true" tabindex="-1"></a>  ...</span>
<span id="cb17-11"><a href="training.html#cb17-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>In certain cases, data points stem from different “groups”, and generalisability across groups is critical. In such cases, data from a given group must not be used both in the training and validation sets. Instead, splits should be made along group delineations. The <em>caret</em> function <code>groupKFold()</code> offers the solution for this case.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="model-formulation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="exercises.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ml4ec_workshop.pdf", "ml4ec_workshop.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
